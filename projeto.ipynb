{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86695769",
   "metadata": {},
   "source": [
    "**Insper**  \n",
    "**Redes Sociais**\n",
    "\n",
    "# Projeto:<br/>Best Books Ever\n",
    "\n",
    "**Jorás Oliveira**  \n",
    "**Luciano Dias**  \n",
    "**Tiago Seixas**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacbb8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import netpixi\n",
    "from ast import literal_eval\n",
    "import seaborn as sns\n",
    "from graph_tool import centrality, spectral, clustering\n",
    "from matplotlib import pyplot as plt\n",
    "from netpixi.integration.gt import *\n",
    "from regression.integration.gt import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regression as reg\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "RANDOM_SEED = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4613dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"books_1.Best_Books_Ever.csv\", usecols=[\"title\", \"series\", \"rating\", \"numRatings\", \"language\", \"genres\"])\n",
    "\n",
    "df['rating'] = minmax_scale(df['rating'])\n",
    "df['numRatings'] = minmax_scale(df['numRatings'])\n",
    "df[\"language\"] = df[\"language\"].map(lambda x: x if x == \"English\" else \"non-English\")\n",
    "df['language'] = df['language'].astype(\"category\")\n",
    "df['genres'] = df['genres'].apply(literal_eval)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae5cb3d",
   "metadata": {},
   "source": [
    "## 1. Construção da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eef8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 1_500\n",
    "\n",
    "RECORTE = 9\n",
    "# 1: Livros que não estão em inglês e que fazem parte de uma série\n",
    "# 2: Livros que estão em inglês e que fazem parte de uma série\n",
    "# 3: Livros que fazem parte de uma série\n",
    "# 4: Livros que não fazem parte de uma série e que não estão em inglês\n",
    "# 5: Livros que não fazem parte de uma série e estão em inglês\n",
    "# 6: Livros que não fazem parte de uma série\n",
    "# 7: Livros que não estão em inglês\n",
    "# 8: Livros que estão em inglês\n",
    "# X: Sem recorte\n",
    "\n",
    "filtered = df\n",
    "\n",
    "if RECORTE in (1, 2, 3):\n",
    "    filtered = filtered.loc[df[\"series\"].notna()]\n",
    "if RECORTE in (4, 5, 6):\n",
    "    filtered = filtered.loc[df[\"series\"].isna()]\n",
    "\n",
    "if RECORTE in (1, 4, 7):\n",
    "    filtered = filtered.loc[df[\"language\"] != \"English\"]\n",
    "if RECORTE in (2, 5, 8):\n",
    "    filtered = filtered.loc[df[\"language\"] == \"English\"]\n",
    "    \n",
    "sample = filtered.sample(SAMPLE_SIZE, replace=False, random_state=RANDOM_SEED)\n",
    "\n",
    "g = Graph(directed=False) # não dirigido\n",
    "g.add_vp('rating')\n",
    "g.add_vp('clustering')\n",
    "g.add_ep('weight')\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eeabca",
   "metadata": {},
   "source": [
    "### 1.1. Operacionalização dos Vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f653191",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in sample.iterrows():\n",
    "    vertex = g.add_vertex(index)\n",
    "    vertex[\"rating\"] = row[\"rating\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5151fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = g.num_vertices()\n",
    "\n",
    "f\"{n} vertices na rede.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001382db",
   "metadata": {},
   "source": [
    "#### 1.1.1 Histograma de pesos dos vértices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66920bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(sample[\"rating\"], binrange=(0, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64897f36",
   "metadata": {},
   "source": [
    "### 1.2. Operacionalização das Arestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_edges = n * (n - 1)\n",
    "\n",
    "f\"{max_edges} arestas possíveis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792948e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(g1, r1, n1, g2, r2, n2):\n",
    "    inter, i1, i2 = np.intersect1d(g1, g2, return_indices=True)\n",
    "   \n",
    "    if len(inter) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    coef_1 = 1 - max(r1, r2) + min(r1, r2)\n",
    "    coef_2 = 1 - max(n1, n2) + min(n1, n2)\n",
    "    coef_3 = np.power((\n",
    "        sum((\n",
    "                (len(g1) - i1) + (len(g2) - i2)\n",
    "            ) / (len(g1) + len(g2))\n",
    "        ) / len(inter)\n",
    "    ), 1 / len(inter))\n",
    "   \n",
    "    return coef_1 * coef_2 * coef_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f96f72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combinations = itertools.combinations(sample.index, 2)\n",
    "weights = []\n",
    "\n",
    "for index, (id_1, id_2) in enumerate(combinations):\n",
    "    row_1 = sample.loc[id_1]\n",
    "    row_2 = sample.loc[id_2]\n",
    "    weight = get_weight(row_1[\"genres\"], row_1[\"rating\"], row_1[\"numRatings\"],\n",
    "                        row_2[\"genres\"], row_2[\"rating\"], row_2[\"numRatings\"])\n",
    "\n",
    "    if weight > 0.5:\n",
    "        edge = g.add_edge(id_1, id_2)\n",
    "        edge[\"weight\"] = weight\n",
    " \n",
    "        weights.append(weight)\n",
    "\n",
    "    if (index*2) % 1_000 == 0:\n",
    "        print(f\"\\r{index*2} {(index*200)//max_edges}%\", end=\"\")\n",
    "\n",
    "print(f\"\\r{max_edges} 100%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b7f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = g.num_edges()\n",
    "\n",
    "f\"{m} arestas na rede. Densidade de {m/max_edges:.5f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f13f93",
   "metadata": {},
   "source": [
    "#### 1.2.1 Histograma de pessos das arestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9796e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(weights, binrange=(0, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b01513",
   "metadata": {},
   "source": [
    "#### 1.2.2 Histograma de degree dos vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7354fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gt_data(g)\n",
    "sample[\"degree\"] = pd.Series([v.total_degree() for v in g.all_vertices()], index=sample.index)\n",
    "\n",
    "sns.histplot(sample[\"degree\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c2a0a8",
   "metadata": {},
   "source": [
    "### 1.3. Limpeza da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e88ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_vertexes = sample.loc[sample[\"degree\"] <= 1].index\n",
    "sample = sample.drop(clear_vertexes)\n",
    "\n",
    "for vertex in clear_vertexes:\n",
    "    g.remove_vertex(vertex)\n",
    "\n",
    "len(clear_vertexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f5dcd2",
   "metadata": {},
   "source": [
    "## 2.  Regressão dos dados da rede\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aecda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"clustering\"] = pd.Series(clustering.local_clustering(g), index=sample.index)\n",
    "\n",
    "for vertex, value in sample[\"clustering\"].items():\n",
    "    g.vertex_properties[\"clustering\"][vertex] = value\n",
    "\n",
    "sns.histplot(sample[\"clustering\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5812544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = reg.linear(data=sample, formula='rating ~ clustering + language')\n",
    "\n",
    "result.micro_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f14666",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot_residuals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0df61",
   "metadata": {},
   "source": [
    "### 1.3. Limpeza da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118838f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gt_draw.sfdp_layout(g)\n",
    "\n",
    "gt_move(g, m)\n",
    "gt_save(g, 'best-books-ever.net.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ac071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = netpixi.render('best-books-ever.net.gz', infinite=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.edge_scale('weight', 1, 10)\n",
    "r.vertex_scale('clustering', 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c93a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"clustering\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1c60e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
